{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FistDetector:\n",
    "    def __init__(self):\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False,\n",
    "            max_num_hands=2,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_draw = mp.solutions.drawing_utils\n",
    "        self.fist_count = 0\n",
    "        self.last_fist_state = False\n",
    "\n",
    "    def detect_fist(self, image):\n",
    "        # Convert the BGR image to RGB\n",
    "        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the image and detect hands\n",
    "        results = self.hands.process(rgb_image)\n",
    "        \n",
    "        current_fist_detected = False\n",
    "        \n",
    "        # Check if any hands are detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks\n",
    "                self.mp_draw.draw_landmarks(\n",
    "                    image, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                # Get the coordinates of the thumb and index finger\n",
    "                thumb_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.THUMB_TIP]\n",
    "                index_tip = hand_landmarks.landmark[self.mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                \n",
    "                # Calculate the distance between thumb and index finger\n",
    "                distance = np.sqrt((thumb_tip.x - index_tip.x)**2 + \n",
    "                                 (thumb_tip.y - index_tip.y)**2)\n",
    "                \n",
    "                # If the distance is small, it's likely a fist\n",
    "                if distance < 0.1:\n",
    "                    current_fist_detected = True\n",
    "                    # Draw a rectangle around the fist\n",
    "                    h, w, c = image.shape\n",
    "                    x_min = int(min(thumb_tip.x, index_tip.x) * w)\n",
    "                    y_min = int(min(thumb_tip.y, index_tip.y) * h)\n",
    "                    x_max = int(max(thumb_tip.x, index_tip.x) * w)\n",
    "                    y_max = int(max(thumb_tip.y, index_tip.y) * h)\n",
    "                    \n",
    "                    cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "                    cv2.putText(image, \"Fist Detected\", (x_min, y_min - 10),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "        \n",
    "        # Update fist count if a new fist is detected\n",
    "        if current_fist_detected and not self.last_fist_state:\n",
    "            self.fist_count += 1\n",
    "        \n",
    "        self.last_fist_state = current_fist_detected\n",
    "        \n",
    "        # Display the fist count\n",
    "        cv2.putText(image, f\"Fist Count: {self.fist_count}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def reset_count(self):\n",
    "        self.fist_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = FistDetector()\n",
    "\n",
    "while True:\n",
    "    # Read frame from webcam\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to read from webcam\")\n",
    "        break\n",
    "\n",
    "    # Flip the image horizontally for a later selfie-view display\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    # Detect fists\n",
    "    image = detector.detect_fist(image)\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Fist Detection\", image)\n",
    "\n",
    "    # Check for key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        detector.reset_count()\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
